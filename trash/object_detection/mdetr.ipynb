{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install timm==0.4.5 transformers==4.6\n",
    "#! pip install matplotlib scikit-image\n",
    "#! pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "import cv2\n",
    "\n",
    "def add_rectangle_on_frame(frame, coordinates, title):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        frame (_type_): _description_\n",
    "        coordinates (_type_): in x0, y0, w, h \n",
    "        text (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Add a rectangle to the frame\n",
    "    rectangle_color = (0, 255, 0)  # Green color\n",
    "    rectangle_thickness = 2\n",
    "    coordinates = [int(i) for i in coordinates]\n",
    "    cv2.rectangle(frame, (coordinates[0], coordinates[1]), (coordinates[0]+coordinates[2], coordinates[1]+coordinates[3]), rectangle_color, rectangle_thickness)\n",
    "\n",
    "    # Add a title to the frame\n",
    "    \n",
    "    \"\"\"title_position = (coordinates[0], coordinates[1]-2)\n",
    "    title_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    title_font_scale = 1\n",
    "    title_color = (0, 255, 0)  # Green color\n",
    "    cv2.putText(frame, title, title_position, title_font, title_font_scale, title_color, rectangle_thickness, cv2.LINE_AA)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()\"\"\"\n",
    "    return frame \n",
    "  \n",
    "def plot_results2(pil_img, scores, boxes, labels, masks=None):\n",
    "    \n",
    "    frame = np.array(pil_img)\n",
    "    colors = COLORS * 100\n",
    "    if masks is None:\n",
    "      masks = [None for _ in range(len(scores))]\n",
    "    for s, (xmin, ymin, xmax, ymax), l, mask, c in zip(scores, boxes.tolist(), labels, masks, colors):\n",
    "        coordinates = [xmin, ymin, -xmin+xmax, -ymin+ymax]    \n",
    "        frame= add_rectangle_on_frame(frame, coordinates, \": \")\n",
    "    #for pig_id,pig in enumerate(boxes):\n",
    "        \n",
    "   \n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_results(pil_img, scores, boxes, labels, masks=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    np_image = np.array(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if masks is None:\n",
    "      masks = [None for _ in range(len(scores))]\n",
    "    assert len(scores) == len(boxes) == len(labels) == len(masks)\n",
    "    for s, (xmin, ymin, xmax, ymax), l, mask, c in zip(scores, boxes.tolist(), labels, masks, colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        text = f'{l}: {s:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "        \"\"\"if mask is None:\n",
    "          continue\n",
    "        np_image = apply_mask(np_image, mask, c)\n",
    "\n",
    "        padded_mask = np.zeros((mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "          # Subtract the padding and flip (y, x) to (x, y)\n",
    "          verts = np.fliplr(verts) - 1\n",
    "          p = Polygon(verts, facecolor=\"none\", edgecolor=c)\n",
    "          ax.add_patch(p)\"\"\"\n",
    "\n",
    "\n",
    "    plt.imshow(np_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_res(results, ax, color='green'):\n",
    "    #for tt in results.values():\n",
    "    if True:\n",
    "        bboxes = results['boxes']\n",
    "        labels = results['labels']\n",
    "        scores = results['scores']\n",
    "        #keep = scores >= 0.0\n",
    "        #bboxes = bboxes[keep].tolist()\n",
    "        #labels = labels[keep].tolist()\n",
    "        #scores = scores[keep].tolist()\n",
    "    #print(torchvision.ops.box_iou(tt['boxes'].cpu().detach(), torch.as_tensor([[xmin, ymin, xmax, ymax]])))\n",
    "    \n",
    "    colors = ['purple', 'yellow', 'red', 'green', 'orange', 'pink']\n",
    "    \n",
    "    for i, (b, ll, ss) in enumerate(zip(bboxes, labels, scores)):\n",
    "        ax.add_patch(plt.Rectangle((b[0], b[1]), b[2] - b[0], b[3] - b[1], fill=False, color=colors[i], linewidth=3))\n",
    "        cls_name = ll if isinstance(ll,str) else CLASSES[ll]\n",
    "        text = f'{cls_name}: {ss:.2f}'\n",
    "        ax.text(b[0], b[1], text, fontsize=15, bbox=dict(facecolor='white', alpha=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, postprocessor = torch.hub.load('ashkamath/mdetr:main', 'mdetr_efficientnetB5', pretrained=True, return_postprocessor=True)\n",
    "#model = model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nms import nms , malisiewicz, fast\n",
    "\n",
    "\n",
    "\n",
    "def plot_inference(im, caption):\n",
    "  # mean-std normalize the input image (batch-size: 1)\n",
    "  img = transform(im).unsqueeze(0)#.cuda()\n",
    "\n",
    "  # propagate through the model\n",
    "  memory_cache = model(img, [caption], encode_and_save=True)\n",
    "  outputs = model(img, [caption], encode_and_save=False, memory_cache=memory_cache)\n",
    "  \n",
    "  # keep only predictions with 0.7+ confidence\n",
    "  probas = 1 - outputs['pred_logits'].softmax(-1)[0, :, -1].cpu()\n",
    "  keep = (probas > 0.2).cpu()\n",
    "\n",
    "  \n",
    "  ############NMS\n",
    "  \"\"\"bboxes_scaled = rescale_bboxes(outputs['pred_boxes'].cpu()[0, :], im.size)\n",
    "  bboxes_scaled_tlw= [[int(box[0]),int(box[1]), int(box[2]-box[0]), int(box[3]-box[1]) ]   for box in bboxes_scaled]\n",
    "  best_keep_nms = nms.boxes(bboxes_scaled_tlw, probas, nms_algorithm=fast.nms, nms_threshold=0.4)\n",
    "  best_keep_nms = np.array( [ True if (idx in best_keep_nms) else False for idx, i in enumerate(keep) ] )\n",
    "  \n",
    "  keep =keep & best_keep_nms\"\"\"\n",
    "  #print(\"***\",keep, best_keep_nms)\n",
    "  \n",
    "  \n",
    "  \n",
    "  # convert boxes from [0; 1] to image scales\n",
    "  bboxes_scaled = rescale_bboxes(outputs['pred_boxes'].cpu()[0, keep], im.size)\n",
    "  # Extract the text spans predicted by each box\n",
    "  positive_tokens = (outputs[\"pred_logits\"].cpu()[0, keep].softmax(-1) > 0.1).nonzero().tolist()\n",
    "  predicted_spans = defaultdict(str)\n",
    "  for tok in positive_tokens:\n",
    "    item, pos = tok\n",
    "    if pos < 255:\n",
    "        span = memory_cache[\"tokenized\"].token_to_chars(0, pos)\n",
    "        predicted_spans [item] += \" \" + caption[span.start:span.end]\n",
    "\n",
    "  labels = [predicted_spans [k] for k in sorted(list(predicted_spans .keys()))]\n",
    "  \n",
    "  print(len(probas[keep]), len(bboxes_scaled) ,len(labels))\n",
    "  assert len(probas[keep])== len(bboxes_scaled) ==len(labels)\n",
    "  plot_results(im, probas[keep], bboxes_scaled, labels)\n",
    "  plot_results2(im, probas[keep], bboxes_scaled, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_inference(im, \"5 people each holding an umbrella\")\n",
    "\n",
    "import cv2 \n",
    "video_file = \"/home/sophie/aggression_detection/annotated/2019_11_22/000010/color.mp4\"\n",
    "\n",
    "processed_frames = []\n",
    "video_capture = cv2.VideoCapture(video_file)  # Replace with your video file path\n",
    "frame_id=0\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if not ret  or frame_id==30:\n",
    "        break\n",
    "    \n",
    "    if frame_id >25:\n",
    "        print(ret)\n",
    "        frame=Image.fromarray(frame)\n",
    "        processed_frame = plot_inference (frame, \"pigs\") \n",
    "        print(\"*****\",frame_id)\n",
    "    frame_id+=1\n",
    "    \n",
    "\"\"\" processed_frames.append(processed_frame)\n",
    "    frame_id+=1\n",
    "\n",
    "def key_function(item):\n",
    "    return list(item.keys())[0]\n",
    "\n",
    "# Use argsort with the custom key function to sort the array\n",
    "sorted_indices = np.argsort(np.array([key_function(item) for item in processed_frames]))\n",
    "sorted_processed_frames = np.array(processed_frames)[sorted_indices]\n",
    "sorted_processed_frames= sorted_processed_frames.tolist()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bytetracker import BYTETracker\n",
    "help(BYTETracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdetr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
